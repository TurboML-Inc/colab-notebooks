{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Python Model: Batch Example\n",
    "\n",
    "In this example we emulate batch training of custom models defined using TurboML's `Python` model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab11eb6",
   "metadata": {},
   "source": [
    "Clone the repo with notebooks and corresponding data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/TurboML-Inc/colab-notebooks.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d10b5b",
   "metadata": {},
   "source": [
    "Set up the environment and install TurboML's SDK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a91555",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()\n",
    "!bash colab-notebooks/install_turboml.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0307ef6f",
   "metadata": {},
   "source": [
    "The kernel should now be restarted with TurboML's SDK installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8bda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd colab-notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf9b9b7",
   "metadata": {},
   "source": [
    "Login to your TurboML instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ee9fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import turboml as tb\n",
    "tb.init(backend_url=BACKEND_URL, api_key=API_KEY)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "Here we define `MyBatchModel` with buffers to store the input features and labels until we exceed our buffer limit. Then, the model can be brained all at once on the buffered samples.\n",
    "\n",
    "We use `Scikit-Learn`'s `Perceptron` for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "import turboml.common.pytypes as types\n",
    "\n",
    "\n",
    "class MyBatchModel:\n",
    "    def __init__(self):\n",
    "        self.model = Perceptron()\n",
    "        self.X_buffer = []\n",
    "        self.y_buffer = []\n",
    "        self.batch_size = 64\n",
    "        self.trained = False\n",
    "\n",
    "    def init_imports(self):\n",
    "        from sklearn.linear_model import Perceptron\n",
    "        import numpy as np\n",
    "\n",
    "    def learn_one(self, input: types.InputData):\n",
    "        self.X_buffer.append(input.numeric)\n",
    "        self.y_buffer.append(input.label)\n",
    "\n",
    "        if len(self.X_buffer) >= self.batch_size:\n",
    "            self.model = self.model.partial_fit(\n",
    "                np.array(self.X_buffer), np.array(self.y_buffer), classes=[0, 1]\n",
    "            )\n",
    "\n",
    "            self.X_buffer = []\n",
    "            self.y_buffer = []\n",
    "\n",
    "            self.trained = True\n",
    "\n",
    "    def predict_one(self, input: types.InputData, output: types.OutputData):\n",
    "        if self.trained:\n",
    "            prediction = self.model.predict(np.array(input.numeric).reshape(1, -1))[0]\n",
    "\n",
    "            output.set_predicted_class(prediction)\n",
    "        else:\n",
    "            output.set_score(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Now, we define a custom virtual environment with the correct list of dependencies which the model will be using, and link our model to this `venv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "venv = tb.setup_venv(\"my_batch_python_venv\", [\"scikit-learn\", \"numpy<2\"])\n",
    "venv.add_python_class(MyBatchModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Once the virtual environment is ready, we prepare the dataset to be used in this task and deploy the model with its features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_model = tb.Python(class_name=MyBatchModel.__name__, venv_name=venv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv(\"data/transactions.csv\").reset_index()\n",
    "labels_df = pd.read_csv(\"data/labels.csv\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    transactions = tb.PandasDataset(\n",
    "        dataset_name=\"transactions_batch_python\",\n",
    "        key_field=\"index\",\n",
    "        dataframe=transactions_df,\n",
    "        upload=True,\n",
    "    )\n",
    "except:\n",
    "    transactions = tb.PandasDataset(dataset_name=\"transactions_batch_python\")\n",
    "\n",
    "try:\n",
    "    labels = tb.PandasDataset(\n",
    "        dataset_name=\"labels_batch_python\",\n",
    "        key_field=\"index\",\n",
    "        dataframe=labels_df,\n",
    "        upload=True,\n",
    "    )\n",
    "except:\n",
    "    labels = tb.PandasDataset(dataset_name=\"labels_batch_python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_fields = [\n",
    "    \"transactionAmount\",\n",
    "    \"localHour\",\n",
    "    \"isProxyIP\",\n",
    "    \"digitalItemCount\",\n",
    "    \"physicalItemCount\",\n",
    "]\n",
    "features = transactions.get_input_fields(numerical_fields=numerical_fields)\n",
    "label = labels.get_label_field(label_field=\"is_fraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_batch_model = batch_model.deploy(\"batch_model\", input=features, labels=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "deployed_batch_model.add_metric(\"WindowedRMSE\")\n",
    "model_auc_scores = deployed_batch_model.get_evaluation(\"WindowedRMSE\")\n",
    "plt.plot([model_auc_score.metric for model_auc_score in model_auc_scores])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
