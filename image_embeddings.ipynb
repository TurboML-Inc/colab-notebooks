{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing (MNIST Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone the repo with notebooks and corresponding data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/TurboML-Inc/colab-notebooks.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the environment and install TurboML's SDK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()\n",
    "!bash colab-notebooks/install_turboml.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel should now be restarted with TurboML's SDK installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd colab-notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to your TurboML instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import turboml as tb\n",
    "tb.init(backend_url=BACKEND_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing and importing `torchvision` along with other necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import io\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PILToBytes:\n",
    "    def __init__(self, format=\"JPEG\"):\n",
    "        self.format = format\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if not isinstance(img, Image.Image):\n",
    "            raise TypeError(f\"Input should be a PIL Image, but got {type(img)}.\")\n",
    "        buffer = io.BytesIO()\n",
    "        img.save(buffer, format=self.format)\n",
    "        return buffer.getvalue()\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((28, 28)),\n",
    "        PILToBytes(format=\"PNG\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection\n",
    "\n",
    "Downloading the MNIST dataset to be used in ML modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset_train = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "mnist_dataset_test = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = []\n",
    "images_test = []\n",
    "labels_train = []\n",
    "labels_test = []\n",
    "\n",
    "for image, label in mnist_dataset_train:\n",
    "    images_train.append(image)\n",
    "    labels_train.append(label)\n",
    "\n",
    "for image, label in mnist_dataset_test:\n",
    "    images_test.append(image)\n",
    "    labels_test.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the lists into Pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict_train = {\"images\": images_train}\n",
    "label_dict_train = {\"labels\": labels_train}\n",
    "image_df_train = pd.DataFrame(image_dict_train)\n",
    "label_df_train = pd.DataFrame(label_dict_train)\n",
    "\n",
    "image_dict_test = {\"images\": images_test}\n",
    "label_dict_test = {\"labels\": labels_test}\n",
    "image_df_test = pd.DataFrame(image_dict_test)\n",
    "label_df_test = pd.DataFrame(label_dict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding index columns to the DataFrames to act as primary keys for the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df_train.reset_index(inplace=True)\n",
    "label_df_train.reset_index(inplace=True)\n",
    "\n",
    "image_df_test.reset_index(inplace=True)\n",
    "label_df_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df_test = image_df_test[:5].reset_index(drop=True)\n",
    "label_df_test = label_df_test[:5].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `PandasDataset` class for compatibility with the TurboML platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = tb.PandasDataset(\n",
    "    dataframe=image_df_train, key_field=\"index\", streaming=False\n",
    ")\n",
    "labels_train = tb.PandasDataset(\n",
    "    dataframe=label_df_train, key_field=\"index\", streaming=False\n",
    ")\n",
    "\n",
    "images_test = tb.PandasDataset(\n",
    "    dataframe=image_df_test, key_field=\"index\", streaming=False\n",
    ")\n",
    "labels_test = tb.PandasDataset(\n",
    "    dataframe=label_df_test, key_field=\"index\", streaming=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the features and the targets from the TurboML-compatible datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaginal_fields = [\"images\"]\n",
    "\n",
    "features_train = images_train.get_input_fields(imaginal_fields=imaginal_fields)\n",
    "targets_train = labels_train.get_label_field(label_field=\"labels\")\n",
    "\n",
    "features_test = images_test.get_input_fields(imaginal_fields=imaginal_fields)\n",
    "targets_test = labels_test.get_label_field(label_field=\"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip Model Initialization\n",
    "\n",
    "We Simply create a ClipEmbedding model with gguf_model. The CLIP model is pulled from the Huggingface repository. As it is already quantized, we can directly pass the model file name in 'select_model_file' parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gguf_model = tb.acquire_hf_model_as_gguf(\n",
    "    \"xtuner/llava-llama-3-8b-v1_1-gguf\", \"auto\", \"llava-llama-3-8b-v1_1-mmproj-f16.gguf\"\n",
    ")\n",
    "gguf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tb.ClipEmbedding(gguf_model_id=gguf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Setting the model combined with the `ImageToNumeric PreProcessor` to learn on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.learn(features_train, targets_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference\n",
    "\n",
    "Performing inference on the trained model using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_test = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
