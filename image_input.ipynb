{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing (MNIST Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone the repo with notebooks and corresponding data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/TurboML-Inc/colab-notebooks.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd colab-notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing and importing `torchvision` along with other necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the environment and install TurboML's SDK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()\n",
    "!bash install_turboml.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to your TurboML instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import turboml as tb\n",
    "tb.init(backend_url=BACKEND_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import io\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PILToBytes:\n",
    "    def __init__(self, format=\"JPEG\"):\n",
    "        self.format = format\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if not isinstance(img, Image.Image):\n",
    "            raise TypeError(f\"Input should be a PIL Image, but got {type(img)}.\")\n",
    "        buffer = io.BytesIO()\n",
    "        img.save(buffer, format=self.format)\n",
    "        return buffer.getvalue()\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((28, 28)),\n",
    "        PILToBytes(format=\"PNG\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection\n",
    "\n",
    "Downloading the MNIST dataset to be used in ML modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset_train = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "mnist_dataset_test = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = []\n",
    "images_test = []\n",
    "labels_train = []\n",
    "labels_test = []\n",
    "\n",
    "for image, label in mnist_dataset_train:\n",
    "    images_train.append(image)\n",
    "    labels_train.append(label)\n",
    "\n",
    "for image, label in mnist_dataset_test:\n",
    "    images_test.append(image)\n",
    "    labels_test.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the lists into Pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict_train = {\"images\": images_train}\n",
    "label_dict_train = {\"labels\": labels_train}\n",
    "image_df_train = pd.DataFrame(image_dict_train)\n",
    "label_df_train = pd.DataFrame(label_dict_train)\n",
    "\n",
    "image_dict_test = {\"images\": images_test}\n",
    "label_dict_test = {\"labels\": labels_test}\n",
    "image_df_test = pd.DataFrame(image_dict_test)\n",
    "label_df_test = pd.DataFrame(label_dict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding index columns to the DataFrames to act as primary keys for the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df_train.reset_index(inplace=True)\n",
    "label_df_train.reset_index(inplace=True)\n",
    "\n",
    "image_df_test.reset_index(inplace=True)\n",
    "label_df_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `PandasDataset` class for compatibility with the TurboML platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = tb.PandasDataset(\n",
    "    dataframe=image_df_train, key_field=\"index\", streaming=False\n",
    ")\n",
    "labels_train = tb.PandasDataset(\n",
    "    dataframe=label_df_train, key_field=\"index\", streaming=False\n",
    ")\n",
    "\n",
    "images_test = tb.PandasDataset(\n",
    "    dataframe=image_df_test, key_field=\"index\", streaming=False\n",
    ")\n",
    "labels_test = tb.PandasDataset(\n",
    "    dataframe=label_df_test, key_field=\"index\", streaming=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the features and the targets from the TurboML-compatible datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaginal_fields = [\"images\"]\n",
    "\n",
    "features_train = images_train.get_input_fields(imaginal_fields=imaginal_fields)\n",
    "targets_train = labels_train.get_label_field(label_field=\"labels\")\n",
    "\n",
    "features_test = images_test.get_input_fields(imaginal_fields=imaginal_fields)\n",
    "targets_test = labels_test.get_label_field(label_field=\"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "\n",
    "Defining a Neural Network (NN) to be used on the MNIST data.\n",
    "\n",
    "The `output_size` of the final layer in the NN is `10` in the case of MNIST.\n",
    "\n",
    "Since this is a classification task, `Cross Entropy` loss is used with the `Adam` optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_layer = tb.NNLayer(output_size=10, activation=\"none\")\n",
    "\n",
    "model = tb.NeuralNetwork(\n",
    "    loss_function=\"cross_entropy\", optimizer=\"adam\", learning_rate=0.01\n",
    ")\n",
    "model.layers[-1] = final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageToNumeric PreProcessor\n",
    "\n",
    "Since we are dealing with images as input to the model, we select the `ImageToNumeric PreProcessor` to accordingly convert the binary images into numerical data useful to the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tb.ImageToNumericPreProcessor(base_model=model, image_sizes=[28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Setting the model combined with the `ImageToNumeric PreProcessor` to learn on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.learn(features_train, targets_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference\n",
    "\n",
    "Performing inference on the trained model using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_test = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing\n",
    "\n",
    "Testing the trained model's performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test_list = labels_test.input_df[\"labels\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Accuracy: \",\n",
    "    metrics.accuracy_score(labels_test_list, outputs_test[\"predicted_class\"]),\n",
    ")\n",
    "print(\n",
    "    \"F1: \",\n",
    "    metrics.f1_score(\n",
    "        labels_test_list, outputs_test[\"predicted_class\"], average=\"macro\"\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    \"Precision: \",\n",
    "    metrics.precision_score(\n",
    "        labels_test_list, outputs_test[\"predicted_class\"], average=\"macro\"\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
