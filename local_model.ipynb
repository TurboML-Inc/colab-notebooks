{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Local Model\n",
    "LocalModel is our Python interface that gives direct access to TurboML's machine learning models. \n",
    "\n",
    "We will use the transactions.csv and labels.csv datasets for our experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00eb789",
   "metadata": {},
   "source": [
    "Set up the environment and install TurboML's SDK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()\n",
    "! conda install -qq conda-forge::libstdcxx-ng anaconda::protobuf\n",
    "! gdown -q 1UG8cmBLdYtEVJZG8Rgz454l722VAt_zE\n",
    "! unzip -qq turboml.zip -d turboml && pip install -qq turboml/*.whl && rm -rf turboml turboml.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73604f54",
   "metadata": {},
   "source": [
    "Login to your TurboML instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09644f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import turboml as tb\n",
    "tb.init(backend_url=BACKEND_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from turboml import LocalModel\n",
    "from turboml.common.models import InputSpec\n",
    "from turboml.common.dataloader import Inputs, Labels, PandasDataset\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "transactions_df = pd.read_csv(\"data/transactions.csv\").reset_index()\n",
    "labels_df = pd.read_csv(\"data/labels.csv\").reset_index()\n",
    "\n",
    "# Use the first 100,000 records for training\n",
    "transactions_100k = PandasDataset(\n",
    "    dataframe=transactions_df[:100000], key_field=\"index\", streaming=False\n",
    ")\n",
    "labels_100k = PandasDataset(\n",
    "    dataframe=labels_df[:100000], key_field=\"index\", streaming=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Define Input Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_fields = [\n",
    "    \"transactionAmount\",\n",
    "    \"localHour\",\n",
    "]\n",
    "\n",
    "categorical_fields = [\n",
    "    \"digitalItemCount\",\n",
    "    \"physicalItemCount\",\n",
    "    \"isProxyIP\",\n",
    "]\n",
    "\n",
    "input_spec = InputSpec(\n",
    "    key_field=\"index\",\n",
    "    numerical_fields=numerical_fields,\n",
    "    categorical_fields=categorical_fields,\n",
    "    textual_fields=[],\n",
    "    imaginal_fields=[],\n",
    "    time_field=\"\",\n",
    "    label_field=\"is_fraud\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Prepare Input and Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = Inputs(\n",
    "    dataset_id=\"transactions_topic\",\n",
    "    dataframe=transactions_df[:100000],\n",
    "    key_field=\"index\",\n",
    "    numerical_fields=numerical_fields,\n",
    "    categorical_fields=categorical_fields,\n",
    ")\n",
    "\n",
    "label_data = Labels(\n",
    "    dataset_id=\"labels_topic\",\n",
    "    dataframe=labels_df[:100000],\n",
    "    key_field=\"index\",\n",
    "    label_field=\"is_fraud\",\n",
    ")\n",
    "\n",
    "test_input_data = Inputs(\n",
    "    dataset_id=\"test_transactions_topic\",\n",
    "    dataframe=transactions_df[100000:120000],\n",
    "    key_field=\"index\",\n",
    "    numerical_fields=numerical_fields,\n",
    "    categorical_fields=categorical_fields,\n",
    ")\n",
    "\n",
    "test_label_data = Labels(\n",
    "    dataset_id=\"test_labels_topic\",\n",
    "    dataframe=labels_df[100000:120000],\n",
    "    key_field=\"index\",\n",
    "    label_field=\"is_fraud\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Define Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"HoeffdingTree\": [\n",
    "        {\n",
    "            \"algorithm\": \"HoeffdingTreeClassifier\",\n",
    "            \"hoeffding_classifier_config\": {\n",
    "                \"delta\": 1e-7,\n",
    "                \"tau\": 0.05,\n",
    "                \"grace_period\": 200,\n",
    "                \"n_classes\": 2,\n",
    "                \"leaf_pred_method\": \"mc\",\n",
    "                \"split_method\": \"gini\",\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    \"AMF\": [\n",
    "        {\n",
    "            \"algorithm\": \"AMFClassifier\",\n",
    "            \"amf_classifier_config\": {\n",
    "                \"n_classes\": 2,\n",
    "                \"n_estimators\": 10,\n",
    "                \"step\": 1,\n",
    "                \"use_aggregation\": True,\n",
    "                \"dirichlet\": 0.5,\n",
    "                \"split_pure\": False,\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    \"MultinomialNB\": [\n",
    "        {\n",
    "            \"algorithm\": \"MultinomialNB\",\n",
    "            \"multinomial_config\": {\"n_classes\": 2, \"alpha\": 1.0},\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Training and Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(name, config):\n",
    "    try:\n",
    "        # Create LocalModel\n",
    "        model = LocalModel(\n",
    "            model_configs=config,\n",
    "            input_spec=input_spec,\n",
    "        )\n",
    "\n",
    "        print(f\"Training {name} model on first 100K records...\")\n",
    "        model.learn(input_data, label_data)\n",
    "\n",
    "        # Make predictions on test data\n",
    "        predictions = model.predict(test_input_data)\n",
    "\n",
    "        # Evaluate model performance\n",
    "        roc_auc = metrics.roc_auc_score(\n",
    "            test_label_data.dataframe[\"is_fraud\"], predictions[\"score\"]\n",
    "        )\n",
    "        accuracy = metrics.accuracy_score(\n",
    "            test_label_data.dataframe[\"is_fraud\"], predictions[\"predicted_class\"]\n",
    "        )\n",
    "\n",
    "        print(f\"{name} Model Results:\")\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "        print(f\"Accuracy Score: {accuracy:.4f}\")\n",
    "        return model, predictions\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {name} model: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained_100K = {}\n",
    "initial_results = {}\n",
    "\n",
    "for name, config in model_configs.items():\n",
    "    model, predictions = train_and_evaluate(name, config)\n",
    "    if model is not None:\n",
    "        model_trained_100K[name] = model\n",
    "        initial_results[name] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Further Training in Batches\n",
    "We will continue training the Hoeffding Tree model with additional data in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the trained Hoeffding Tree model\n",
    "model_hoeffding_tree = model_trained_100K.get(\"HoeffdingTree\")\n",
    "\n",
    "if model_hoeffding_tree is not None:\n",
    "    # Split the dataset into 10 parts for batch training\n",
    "    data_parts = np.array_split(transactions_df[100000:], 10)\n",
    "    label_parts = np.array_split(labels_df[100000:], 10)\n",
    "\n",
    "    for i, (data_part, label_part) in enumerate(\n",
    "        zip(data_parts, label_parts, strict=False)\n",
    "    ):\n",
    "        print(f\"\\nPreparing batch {i + 1}...\")\n",
    "        df_train_tb = tb.PandasDataset(\n",
    "            dataframe=data_part, key_field=\"index\", streaming=False\n",
    "        )\n",
    "        df_y_train_tb = tb.PandasDataset(\n",
    "            dataframe=label_part, key_field=\"index\", streaming=False\n",
    "        )\n",
    "\n",
    "        features = df_train_tb.get_input_fields(\n",
    "            numerical_fields=numerical_fields,\n",
    "            categorical_fields=categorical_fields,\n",
    "        )\n",
    "        labels = df_y_train_tb.get_label_field(label_field=\"is_fraud\")\n",
    "\n",
    "        print(f\"Training batch {i + 1}...\")\n",
    "        start_time = time.time()\n",
    "        model_hoeffding_tree.learn(features, labels)\n",
    "        end_time = time.time()\n",
    "        print(\n",
    "            f\"Batch {i + 1} training completed in {end_time - start_time:.2f} seconds.\"\n",
    "        )\n",
    "else:\n",
    "    print(\"Hoeffding Tree model not found in trained models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnx==1.14.1 scikit-learn skl2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# Prepare features and target\n",
    "X = transactions_df[numerical_fields + categorical_fields]\n",
    "y = labels_df[\"is_fraud\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train sklearn model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to ONNX format\n",
    "initial_type = [(\"float_input\", FloatTensorType([None, X_train.shape[1]]))]\n",
    "onx = convert_sklearn(\n",
    "    clf, initial_types=initial_type, options={type(clf): {\"zipmap\": False}}\n",
    ")\n",
    "\n",
    "# Get the serialized ONNX model\n",
    "onnx_model_data = onx.SerializeToString()\n",
    "# Base64-encode the ONNX model data\n",
    "model_data_base64 = base64.b64encode(onnx_model_data).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ONNX model config with the encoded model data\n",
    "onnx_model_config = [\n",
    "    {\n",
    "        \"algorithm\": \"ONNX\",\n",
    "        \"onnx_config\": {\n",
    "            \"model_save_name\": \"randomforest\",\n",
    "            \"model_data\": model_data_base64,\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "onnx_input_spec = InputSpec(\n",
    "    key_field=\"index\",\n",
    "    numerical_fields=numerical_fields + categorical_fields,\n",
    "    categorical_fields=[],\n",
    "    textual_fields=[],\n",
    "    imaginal_fields=[],\n",
    "    time_field=\"\",\n",
    "    label_field=\"is_fraud\",\n",
    ")\n",
    "\n",
    "local_onnx_model = LocalModel(\n",
    "    model_configs=onnx_model_config,\n",
    "    input_spec=onnx_input_spec,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test input data\n",
    "test_input_data = Inputs(\n",
    "    dataset_id=\"test_transactions_topic\",\n",
    "    dataframe=X_test.reset_index(),\n",
    "    key_field=\"index\",\n",
    "    numerical_fields=numerical_fields + categorical_fields,\n",
    ")\n",
    "\n",
    "test_label_data = Labels(\n",
    "    dataset_id=\"test_labels_topic\",\n",
    "    dataframe=pd.DataFrame({\"index\": X_test.index, \"is_fraud\": y_test}).reset_index(\n",
    "        drop=True\n",
    "    ),\n",
    "    key_field=\"index\",\n",
    "    label_field=\"is_fraud\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_model():\n",
    "    try:\n",
    "        # Get predictions\n",
    "        predictions = local_onnx_model.predict(test_input_data)\n",
    "\n",
    "        # Calculate metrics\n",
    "        roc_auc = metrics.roc_auc_score(\n",
    "            test_label_data.dataframe[\"is_fraud\"],\n",
    "            predictions[\"score\"],\n",
    "        )\n",
    "        accuracy = metrics.accuracy_score(\n",
    "            test_label_data.dataframe[\"is_fraud\"],\n",
    "            predictions[\"predicted_class\"],\n",
    "        )\n",
    "\n",
    "        print(\"ONNX Model Results:\")\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "        print(f\"Accuracy Score: {accuracy:.4f}\")\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error testing ONNX model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Run the test\n",
    "predictions = onnx_model()\n",
    "\n",
    "if predictions is not None:\n",
    "    sklearn_preds = clf.predict(X_test)\n",
    "    onnx_preds = predictions[\"predicted_class\"]\n",
    "\n",
    "    match_rate = (sklearn_preds == onnx_preds).mean()\n",
    "    print(\"\\nPrediction Comparison:\")\n",
    "    print(f\"Sklearn vs ONNX prediction match rate: {match_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Python Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_model_code = \"\"\"\n",
    "from river import linear_model\n",
    "import turboml.common.pytypes as types\n",
    "\n",
    "class MyLogisticRegression:\n",
    "\n",
    "    def init_imports(self):\n",
    "        from river import linear_model\n",
    "        import turboml.common.pytypes as types\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = linear_model.LogisticRegression()\n",
    "\n",
    "    def learn_one(self, input):\n",
    "        # Combine numerical and categorical features into a dictionary\n",
    "        features = {}\n",
    "        features.update({f'num_{i}': val for i, val in enumerate(input.numeric)})\n",
    "        features.update({f'cat_{i}': val for i, val in enumerate(input.categ)})\n",
    "        self.model.learn_one(features, input.label)\n",
    "\n",
    "    def predict_one(self, input, output):\n",
    "        # Combine numerical and categorical features into a dictionary\n",
    "        features = {}\n",
    "        features.update({f'num_{i}': val for i, val in enumerate(input.numeric)})\n",
    "        features.update({f'cat_{i}': val for i, val in enumerate(input.categ)})\n",
    "        proba = self.model.predict_proba_one(features)\n",
    "        score = float(proba.get(True, 0))\n",
    "        output.set_score(score)\n",
    "        output.set_predicted_class(int(score >= 0.5))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model configuration\n",
    "python_model_config = {\n",
    "    \"algorithm\": \"Python\",\n",
    "    \"python_config\": {\n",
    "        \"class_name\": \"MyLogisticRegression\",\n",
    "        \"code\": python_model_code,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create the LocalModel instance\n",
    "local_python_model = LocalModel(\n",
    "    model_configs=[python_model_config],\n",
    "    input_spec=input_spec,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "local_python_model.learn(input_data, label_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = local_python_model.predict(test_input_data)\n",
    "\n",
    "# Evaluate the model\n",
    "roc_auc = metrics.roc_auc_score(\n",
    "    test_label_data.dataframe[\"is_fraud\"], predictions[\"score\"]\n",
    ")\n",
    "accuracy = metrics.accuracy_score(\n",
    "    test_label_data.dataframe[\"is_fraud\"], predictions[\"predicted_class\"]\n",
    ")\n",
    "\n",
    "print(f\"Python Model ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"Python Model Accuracy Score: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Python Ensemble Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base models (already defined and trained)\n",
    "hoeffding_tree_model = model_trained_100K[\"HoeffdingTree\"]\n",
    "amf_classifier_model = model_trained_100K[\"AMF\"]\n",
    "multinomial_nb_model = model_trained_100K[\"MultinomialNB\"]\n",
    "\n",
    "# Extract base model configurations\n",
    "base_model_configs = [\n",
    "    hoeffding_tree_model.model_configs[0],\n",
    "    amf_classifier_model.model_configs[0],\n",
    "    multinomial_nb_model.model_configs[0],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare ensemble model code\n",
    "ensemble_model_code = \"\"\"\n",
    "import turboml.common.pymodel as model\n",
    "from typing import List\n",
    "\n",
    "class MyEnsembleModel:\n",
    "    def __init__(self, base_models: List[model.Model]):\n",
    "        if not base_models:\n",
    "            raise ValueError(\"PythonEnsembleModel requires at least one base model.\")\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def init_imports(self):\n",
    "        import turboml.common.pytypes as types\n",
    "        from typing import List\n",
    "\n",
    "    def learn_one(self, input):\n",
    "        for model in self.base_models:\n",
    "            model.learn_one(input)\n",
    "\n",
    "    def predict_one(self, input, output):\n",
    "        total_score = 0.0\n",
    "        for model in self.base_models:\n",
    "            model_output = model.predict_one(input)\n",
    "            total_score += model_output.score()\n",
    "        average_score = total_score / len(self.base_models)\n",
    "        output.set_score(average_score)\n",
    "        output.set_predicted_class(int(average_score >= 0.5))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ensemble model configuration\n",
    "ensemble_model_config = {\n",
    "    \"algorithm\": \"PythonEnsembleModel\",\n",
    "    \"python_ensemble_config\": {\n",
    "        \"class_name\": \"MyEnsembleModel\",\n",
    "        \"code\": ensemble_model_code,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Combine the ensemble model config and base model configs\n",
    "model_configs = [ensemble_model_config] + base_model_configs\n",
    "\n",
    "# Create the ensemble LocalModel instance\n",
    "ensemble_model = tb.LocalModel(\n",
    "    model_configs=model_configs,\n",
    "    input_spec=input_spec,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ensemble model\n",
    "ensemble_model.learn(input_data, label_data)\n",
    "\n",
    "# Make predictions with the ensemble model\n",
    "ensemble_predictions = ensemble_model.predict(test_input_data)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "roc_auc = metrics.roc_auc_score(\n",
    "    test_label_data.dataframe[\"is_fraud\"], ensemble_predictions[\"score\"]\n",
    ")\n",
    "accuracy = metrics.accuracy_score(\n",
    "    test_label_data.dataframe[\"is_fraud\"], ensemble_predictions[\"predicted_class\"]\n",
    ")\n",
    "\n",
    "print(f\"Ensemble Model ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"Ensemble Model Accuracy Score: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
