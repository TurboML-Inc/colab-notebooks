{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Native Python Models\n",
    "\n",
    "While TurboML offers a wide array of algorithms implemented with performant machine-native code, we also\n",
    "give you the flexibility to use your own models in Python when necessary, allowing the use of any public\n",
    "library from PyPi. Lets walk through some simple examples for model based on [River](https://riverml.xyz/latest/)\n",
    "and [scikit-learn](https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Imports and Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66803512",
   "metadata": {},
   "source": [
    "Clone the repo with notebooks and corresponding data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0922b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/TurboML-Inc/colab-notebooks.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08543f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd colab-notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94813789",
   "metadata": {},
   "source": [
    "Set up the environment and install TurboML's SDK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e1c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()\n",
    "!bash install_turboml.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73751af",
   "metadata": {},
   "source": [
    "Login to your TurboML instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba7e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import turboml as tb\n",
    "tb.init(backend_url=BACKEND_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Prepare an Evaluation Dataset\n",
    "\n",
    "We choose standard Credit Card Fraud dataset that ships with River to evaluate our models on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.CreditCard()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, score = next(iter(dataset))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inputs = []\n",
    "sample_labels = []\n",
    "\n",
    "for sample, score in dataset:\n",
    "    sample_inputs.append(sample)\n",
    "    sample_labels.append({\"score\": score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame.from_dict(sample_inputs)\n",
    "df_labels = pd.DataFrame.from_dict(sample_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_features.drop(\n",
    "    [\"Time\"], axis=1\n",
    ")  # We don't want to use this feature for this example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### And finally load them as datasets in the TurboML Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tb.PandasDataset(\n",
    "    dataset_name=\"cc_feats_native\",\n",
    "    key_field=\"index\",\n",
    "    dataframe=df_features.reset_index(),\n",
    "    upload=True,\n",
    ")\n",
    "labels = tb.PandasDataset(\n",
    "    dataset_name=\"cc_labels_native\",\n",
    "    key_field=\"index\",\n",
    "    dataframe=df_labels.reset_index(),\n",
    "    upload=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Isolate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df_features.columns.tolist()\n",
    "input_features = features.get_input_fields(numerical_fields=numerical_cols)\n",
    "label = labels.get_label_field(label_field=\"score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Structure of User Defined Models\n",
    "\n",
    "A custom Python model must implement 3 instance methods - `learn_one`, `predict_one` and `init_imports`.\n",
    "The interface and usage is described below and explored further in the examples contained in this notebook.\n",
    "\n",
    "```python\n",
    "class CustomModel:\n",
    "    def init_imports(self):\n",
    "        \"\"\"\n",
    "        Import any external symbols/modules used in this class\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def learn_one(self, input: types.InputData):\n",
    "        \"\"\"\n",
    "        Receives labelled data for the model to learn from\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def predict_one(self, input: types.InputData, output: types.OutputData):\n",
    "        \"\"\"\n",
    "        Receives input features for a prediction, must pass output to the\n",
    "        output object\n",
    "        \"\"\"\n",
    "        pass\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Example - Leveraging [River](https://riverml.xyz)\n",
    "\n",
    "River is a popular ML library for online machine learning, river comes with an inbuilt functionality for `learn_one` and `predict_one` out of the box, however it is important to note the differences in input to the User Defined models and the input of river model, which takes a dictionary and label as inputs for a supervised algorithm. In this example we create a custom model using river according to the standards mentioned above and put it in a separate python module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import linear_model\n",
    "import turboml.common.pytypes as types\n",
    "\n",
    "\n",
    "class MyLogisticRegression:\n",
    "    def __init__(self):\n",
    "        self.model = linear_model.LogisticRegression()\n",
    "\n",
    "    def init_imports(self):\n",
    "        from river import linear_model\n",
    "\n",
    "    def learn_one(self, input: types.InputData):\n",
    "        self.model.learn_one(dict(enumerate(input.numeric)), input.label)\n",
    "\n",
    "    def predict_one(self, input: types.InputData, output: types.OutputData):\n",
    "        score = float(self.model.predict_one(dict(enumerate(input.numeric))))\n",
    "        output.set_score(score)\n",
    "\n",
    "        # example: setting embeddings\n",
    "        # output.resize_embeddings(3)\n",
    "        # mut = output.embeddings()\n",
    "        # mut[0] = 1\n",
    "        # mut[1] = 2\n",
    "        # mut[2] = 3\n",
    "\n",
    "        # example: appending to feature scores\n",
    "        # this api is an alternative to resize + set as above,\n",
    "        # but less efficient\n",
    "        # output.append_feature_score(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Since python packages can have multiple external dependencies we can make use of `tb.setup_venv(name_of_venv, [List of packages])`. This can create a virtual environment that enables interaction with the platform and the installation of external dependencies with ease. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "venv = tb.setup_venv(\"my_river_venv\", [\"river\", \"numpy\"])\n",
    "venv.add_python_class(MyLogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "river_model = tb.Python(class_name=MyLogisticRegression.__name__, venv_name=venv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model_river = river_model.deploy(\n",
    "    \"river_model\", input=input_features, labels=label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "deployed_model_river.add_metric(\"WindowedRMSE\")\n",
    "model_auc_scores = deployed_model_river.get_evaluation(\"WindowedRMSE\")\n",
    "plt.plot([model_auc_score.metric for model_auc_score in model_auc_scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Example - An Online Model with Sci-Kit Learn\n",
    "\n",
    "Using Scikit learn you can implement online learning something similar to the code example below using `partial_fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "import numpy as np\n",
    "import turboml.common.pytypes as types\n",
    "\n",
    "\n",
    "class MyPerceptron:\n",
    "    def __init__(self):\n",
    "        self.model = Perceptron()\n",
    "        self.fitted = False\n",
    "\n",
    "    def init_imports(self):\n",
    "        from sklearn.linear_model import Perceptron\n",
    "\n",
    "    def learn_one(self, input: types.InputData):\n",
    "        if not self.fitted:\n",
    "            self.model.partial_fit(\n",
    "                np.array(input.numeric).reshape(1, -1),\n",
    "                np.array(input.label).reshape(-1),\n",
    "                classes=[0, 1],\n",
    "            )\n",
    "            self.fitted = True\n",
    "        else:\n",
    "            self.model.partial_fit(\n",
    "                np.array(input.numeric).reshape(1, -1),\n",
    "                np.array(input.label).reshape(-1),\n",
    "            )\n",
    "\n",
    "    def predict_one(self, input: types.InputData, output: types.OutputData):\n",
    "        if self.fitted:\n",
    "            score = self.model.predict(np.array(input.numeric).reshape(1, -1))[0]\n",
    "            output.set_score(score)\n",
    "        else:\n",
    "            output.set_score(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "venv = tb.setup_venv(\"my_sklearn_venv\", [\"scikit-learn\"])\n",
    "venv.add_python_class(MyPerceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model = tb.Python(class_name=MyPerceptron.__name__, venv_name=venv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model_sklearn = sklearn_model.deploy(\n",
    "    \"sklearn_model\", input=input_features, labels=label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "deployed_model_sklearn.add_metric(\"WindowedRMSE\")\n",
    "model_auc_scores = deployed_model_sklearn.get_evaluation(\"WindowedRMSE\")\n",
    "plt.plot([model_auc_score.metric for model_auc_score in model_auc_scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Example - Leveraging [Vowpal Wabbit](https://vowpalwabbit.org/)\n",
    "\n",
    "Vowpal Wabbit provides fast, efficient, and flexible online machine learning techniques for reinforcement learning, supervised learning, and more.\n",
    "\n",
    "In this example we use the new `vowpal-wabbit-next` Python bindings. Note that we need to transform our input to Vowpal's native text format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vowpal-wabbit-next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vowpal_wabbit_next as vw\n",
    "import turboml.common.pytypes as types\n",
    "\n",
    "\n",
    "class MyVowpalModel:\n",
    "    def __init__(self):\n",
    "        self.vw_workspace = vw.Workspace()\n",
    "        self.vw_parser = vw.TextFormatParser(self.vw_workspace)\n",
    "\n",
    "    def init_imports(self):\n",
    "        import vowpal_wabbit_next as vw\n",
    "\n",
    "    def to_vw_format(self, features, label=None):\n",
    "        \"Convert a feature vector into the Vowpal Wabbit format\"\n",
    "        label_place = f\"{label} \" if label is not None else \"\"\n",
    "        vw_text = f\"{label_place}| {' '.join([f'{idx}:{feat}' for idx, feat in enumerate(features, start=1)])}\\n\"\n",
    "        return self.vw_parser.parse_line(vw_text)\n",
    "\n",
    "    def predict_one(self, input: types.InputData, output: types.OutputData):\n",
    "        vw_format = self.to_vw_format(input.numeric)\n",
    "        output.set_score(self.vw_workspace.predict_one(vw_format))\n",
    "\n",
    "    def learn_one(self, input: types.InputData):\n",
    "        vw_format = self.to_vw_format(input.numeric, input.label)\n",
    "        self.vw_workspace.learn_one(vw_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "In the below cell we make use of the custom virtual environment created before to install new packages in this case vowpalwabbit. We have to ensure that the name of the virtual environment remains the same and we can reuse the virtual environment multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "venv = tb.setup_venv(\"my_vowpal_venv\", [\"vowpal-wabbit-next\"])\n",
    "venv.add_python_class(MyVowpalModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "vw_model = tb.Python(class_name=MyVowpalModel.__name__, venv_name=venv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model_vw = vw_model.deploy(\"vw_model\", input=input_features, labels=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "deployed_model_vw.add_metric(\"WindowedRMSE\")\n",
    "model_auc_scores = deployed_model_vw.get_evaluation(\"WindowedRMSE\")\n",
    "plt.plot([model_auc_score.metric for model_auc_score in model_auc_scores])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
