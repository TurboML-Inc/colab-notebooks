{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Resnet example using gRPC Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This example demonstrates using our gRPC client to perform inference with the pretrained ResNet18 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73499d2b",
   "metadata": {},
   "source": [
    "Set up the environment and install TurboML's SDK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1072257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()\n",
    "! conda install -qq conda-forge::libstdcxx-ng anaconda::protobuf\n",
    "! gdown -q 1UG8cmBLdYtEVJZG8Rgz454l722VAt_zE\n",
    "! unzip -qq turboml.zip -d turboml && pip install -qq turboml/*.whl && rm -rf turboml turboml.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df24a6a7",
   "metadata": {},
   "source": [
    "Login to your TurboML instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d23f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import turboml as tb\n",
    "tb.init(backend_url=BACKEND_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from resnet_grpc_server import serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Start gRPC server for pretrained Resnet18 from jupyter-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "\n",
    "def run_server_in_background(url):\n",
    "    serve(url)  # This will start the gRPC server\n",
    "\n",
    "\n",
    "# Start the server in a separate thread\n",
    "url = \"0.0.0.0:50021\"\n",
    "server_thread = threading.Thread(\n",
    "    target=run_server_in_background, args=(url,), daemon=True\n",
    ")\n",
    "server_thread.start()\n",
    "\n",
    "print(\"gRPC server is running in the background...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Load image Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "\n",
    "# Download latest version\n",
    "target_path = \"./data/animal-image-classification-dataset\"\n",
    "path = kagglehub.dataset_download(\"borhanitrash/animal-image-classification-dataset\")\n",
    "shutil.move(path, target_path)\n",
    "\n",
    "print(\"Dataset stored in:\", target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_dataset = datasets.ImageFolder(root=target_path, transform=transforms.ToTensor())\n",
    "data_loader = DataLoader(animal_dataset, batch_size=32, shuffle=True)\n",
    "images, labels = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Convert images into bytes array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "images_test = []\n",
    "labels_test = []\n",
    "\n",
    "for image_tensor, label in zip(images, labels, strict=False):\n",
    "    image = transforms.ToPILImage()(image_tensor)\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    image.save(img_byte_arr, format=\"JPEG\")\n",
    "    binary_image = img_byte_arr.getvalue()\n",
    "\n",
    "    images_test.append(binary_image)\n",
    "    labels_test.append(label.item())\n",
    "\n",
    "image_dict_test = {\"images\": images_test}\n",
    "label_dict_test = {\"labels\": labels_test}\n",
    "image_df_test = pd.DataFrame(image_dict_test)\n",
    "label_df_test = pd.DataFrame(label_dict_test)\n",
    "image_df_test.reset_index(inplace=True)\n",
    "label_df_test.reset_index(inplace=True)\n",
    "\n",
    "print(f\"Processed {len(images_test)} images.\")\n",
    "print(f\"Image DataFrame shape: {image_df_test.shape}\")\n",
    "print(f\"Label DataFrame shape: {label_df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df_test = image_df_test.reset_index(drop=True)\n",
    "label_df_test = label_df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = tb.PandasDataset(\n",
    "    dataframe=image_df_test, key_field=\"index\", streaming=False\n",
    ")\n",
    "labels_test = tb.PandasDataset(\n",
    "    dataframe=label_df_test, key_field=\"index\", streaming=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "imaginal_fields = [\"images\"]\n",
    "features_test = images_test.get_input_fields(imaginal_fields=imaginal_fields)\n",
    "targets_test = labels_test.get_label_field(label_field=\"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Using TurboML Client to request gRPC server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "grpc_model = tb.GRPCClient(\n",
    "    server_url=\"0.0.0.0:50021\",\n",
    "    connection_timeout=10000,\n",
    "    max_request_time=10000,\n",
    "    max_retries=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = grpc_model.learn(features_test, targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model_trained.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs  # {class,probability}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
