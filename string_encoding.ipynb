{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# String Encoding\n",
    "\n",
    "Textual data needs to be converted into numerical data to be used by ML models. For larger textual data like sentences and paragraphs, we saw in llm_embedding notebook how embeddings from pre-trained languages models can be used. But what about smaller strings, like country name? How do we use such strings as features in our ML models? This notebook covers different encoding methods that TurboML provides for textual features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6345cd5",
   "metadata": {},
   "source": [
    "Clone the repo with notebooks and corresponding data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b066087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/TurboML-Inc/colab-notebooks.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c2f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd colab-notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616726c8",
   "metadata": {},
   "source": [
    "Set up the environment and install TurboML's SDK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25317c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()\n",
    "!bash install_turboml.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e2e4ea",
   "metadata": {},
   "source": [
    "Login to your TurboML instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import turboml as tb\n",
    "tb.init(backend_url=BACKEND_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv(\"data/transactions.csv\").reset_index()\n",
    "labels_df = pd.read_csv(\"data/labels.csv\").reset_index()\n",
    "transactions = tb.PandasDataset(\n",
    "    dataset_name=\"transactions_str_encoding\",\n",
    "    key_field=\"index\",\n",
    "    dataframe=transactions_df,\n",
    "    upload=True,\n",
    ")\n",
    "labels = tb.PandasDataset(\n",
    "    dataset_name=\"labels_str_encoding\",\n",
    "    key_field=\"index\",\n",
    "    dataframe=labels_df,\n",
    "    upload=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_fields = [\n",
    "    \"transactionAmount\",\n",
    "]\n",
    "textual_fields = [\"transactionCurrencyCode\"]\n",
    "features = transactions.get_input_fields(\n",
    "    numerical_fields=numerical_fields, textual_fields=textual_fields\n",
    ")\n",
    "label = labels.get_label_field(label_field=\"is_fraud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Notice that now we're extracting a textual feature called transactionCurrencyCode from our dataset. To make sure that the model finally works with numerical data, we can define preprocessors that transform the textual data to numerical data via some encoding methods. By default, TurboML uses the hashing trick (https://en.wikipedia.org/wiki/Feature_hashing) to automatically hash and convert string data to numeric data. However, TurboML also supports popular encoding methods to handle strings including\n",
    "- LabelPreProcessor\n",
    "- OneHotPreProcessor\n",
    "- TargetPreProcessor\n",
    "- FrequencyPreProcessor\n",
    "- BinaryPreProcessor\n",
    "\n",
    "We'll try an example using FrequencyPreProcessor. For these pre-processors, we need to specify in advance the cardinality of our data, which can be computed as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "htc_model = tb.HoeffdingTreeClassifier(n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_classifier = tb.FrequencyPreProcessor(\n",
    "    text_categories=[len(pd.unique(transactions_df[col])) for col in textual_fields],\n",
    "    base_model=htc_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model = demo_classifier.deploy(\n",
    "    \"demo_classifier_htc\", input=features, labels=label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = deployed_model.get_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_output = outputs[-1]\n",
    "sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
